{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNXuFikCep3V7fTf3JWXAPB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmanMIttu/credit-card-fraud-detection/blob/main/credit_card_fraud_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Credit Card Fraud Detection using Machine Learning\n",
        "### Author: Shaik Aman\n",
        "\n",
        "## Motivation\n",
        "\n",
        "While working in cybersecurity, I frequently encountered situations where large volumes of system activity needed to be examined to identify unusual behavior. This raised a practical question: can a machine automatically learn to recognize suspicious patterns?\n",
        "\n",
        "Financial fraud detection is a real-world example of the same problem. In both cybersecurity and banking systems, abnormal patterns must be identified within massive datasets. This project explores how machine learning models can assist in identifying such anomalies.\n",
        "\n",
        "The objective of this project is to classify transactions as legitimate or fraudulent using historical transaction data and to understand the challenges involved in real-world anomaly detection.\n"
      ],
      "metadata": {
        "id": "ywQS3HdikBPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n"
      ],
      "metadata": {
        "id": "o0LGp2EOkMeP"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"creditcard.csv\")\n",
        "df.head()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "vtomyCpJkNEb",
        "outputId": "a64bb8bd-15a2-4c9f-f88b-9b25247ae5f2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
              "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
              "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
              "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
              "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
              "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
              "\n",
              "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
              "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
              "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
              "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
              "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
              "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
              "\n",
              "        V26       V27       V28  Amount  Class  \n",
              "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
              "1  0.125895 -0.008983  0.014724    2.69      0  \n",
              "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
              "3 -0.221929  0.062723  0.061458  123.50      0  \n",
              "4  0.502292  0.219422  0.215153   69.99      0  \n",
              "\n",
              "[5 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9c804528-7bee-4deb-8746-1032e4bda798\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>...</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9c804528-7bee-4deb-8746-1032e4bda798')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9c804528-7bee-4deb-8746-1032e4bda798 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9c804528-7bee-4deb-8746-1032e4bda798');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Understanding the Dataset\n",
        "\n",
        "The dataset contains anonymized credit card transactions.  \n",
        "Each row represents one transaction.\n",
        "\n",
        "The variable **Class** indicates whether a transaction is fraudulent:\n",
        "0 → legitimate transaction  \n",
        "1 → fraudulent transaction\n",
        "\n",
        "Fraudulent transactions are extremely rare in real systems, making this a difficult classification problem.\n"
      ],
      "metadata": {
        "id": "oq2aB5pXkWiy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Class'].value_counts()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "nPsDlAzIkXxp",
        "outputId": "75b232e2-94c1-44ae-835c-8f8caa2cecd8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Class\n",
              "0    284315\n",
              "1       492\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Class</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>284315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>492</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Observing Class Imbalance\n",
        "\n",
        "The dataset is highly imbalanced: legitimate transactions vastly outnumber fraudulent ones.\n",
        "\n",
        "A model could achieve very high accuracy simply by predicting every transaction as legitimate. However, such a model would be useless. Therefore, metrics such as recall and precision are more important than accuracy alone in fraud detection systems.\n"
      ],
      "metadata": {
        "id": "p8bShdhJkcX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('Class', axis=1)\n",
        "y = df['Class']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X['Amount'] = scaler.fit_transform(X[['Amount']])\n"
      ],
      "metadata": {
        "id": "ixnf0GPgkZaj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing\n",
        "\n",
        "Before training the model:\n",
        "- The target variable is separated\n",
        "- The transaction amount is normalized\n",
        "- Features are prepared for machine learning\n",
        "\n",
        "This simulates how real monitoring systems learn patterns from past transaction data.\n"
      ],
      "metadata": {
        "id": "pABhP5VykhH6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train,y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "g_FHUoh7ke4j",
        "outputId": "133cddc8-ccfd-4873-804b-aebd374c9068"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3755383761.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1348\u001b[0m             \u001b[0mn_threads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n\u001b[0m\u001b[1;32m   1351\u001b[0m             path_func(\n\u001b[1;32m   1352\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1984\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1985\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1986\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1988\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1912\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1914\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1915\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[1;32m    449\u001b[0m                 \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m             ]\n\u001b[0;32m--> 451\u001b[0;31m             opt_res = optimize.minimize(\n\u001b[0m\u001b[1;32m    452\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0mw0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    782\u001b[0m                                  **options)\n\u001b[1;32m    783\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m         res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[1;32m    785\u001b[0m                                callback=callback, **options)\n\u001b[1;32m    786\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/optimize/_lbfgsb_py.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, workers, **unknown_options)\u001b[0m\n\u001b[1;32m    467\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mfx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nfev\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lowest_f\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/_lib/_util.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Send a copy because the user may overwrite it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# The user of this class might want `x` to remain unchanged.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mfx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnfev\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/optimize/_optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;34m\"\"\" returns the function value \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/optimize/_optimize.py\u001b[0m in \u001b[0;36m_compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_linear_loss.py\u001b[0m in \u001b[0;36mloss_gradient\u001b[0;34m(self, coef, X, y, sample_weight, l2_reg_strength, n_threads, raw_prediction)\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_intercept\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m         loss, grad_pointwise = self.base_loss.loss_gradient(\n\u001b[0m\u001b[1;32m    317\u001b[0m             \u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0mraw_prediction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraw_prediction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/_loss/loss.py\u001b[0m in \u001b[0;36mloss_gradient\u001b[0;34m(self, y_true, raw_prediction, sample_weight, loss_out, gradient_out, n_threads)\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0mgradient_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         self.closs.loss_gradient(\n\u001b[0m\u001b[1;32m    259\u001b[0m             \u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0mraw_prediction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraw_prediction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=5000, class_weight='balanced', solver='liblinear')\n",
        "model.fit(X_train,y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "XBYHjtcAmCl_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy:\", accuracy_score(y_test,y_pred))\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHK2YDWkmEFe",
        "outputId": "3853a67d-26fc-48c1-e090-f498e97430a6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9746965813466287\n",
            "[[83155  2152]\n",
            " [   10   126]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.99     85307\n",
            "           1       0.06      0.93      0.10       136\n",
            "\n",
            "    accuracy                           0.97     85443\n",
            "   macro avg       0.53      0.95      0.55     85443\n",
            "weighted avg       1.00      0.97      0.99     85443\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation\n",
        "\n",
        "The confusion matrix and classification report help evaluate the model.\n",
        "\n",
        "In fraud detection, recall is very important because missing a fraudulent transaction can lead to financial loss. The results indicate that machine learning models can identify suspicious behavior patterns even when fraud cases are rare.\n"
      ],
      "metadata": {
        "id": "Kr5SG7ttmL2I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6,4))\n",
        "sns.countplot(x=y)\n",
        "plt.title(\"Fraud vs Non-Fraud Transactions\")\n",
        "plt.savefig(\"fraud_distribution.png\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "RLZYWfAzmJqu",
        "outputId": "b3277f49-4207-4604-c135-68c051c1e2aa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjYAAAGJCAYAAACZwnkIAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAOaNJREFUeJzt3X1cFXXe//E3kBzw5oDInSQpmKUoyRUqkpt3kXiTrWWlrleieZOGluJ9a960tl7p1WqmadYW7W6uprtaaqGst5thJmbelF7eUNbqwVs4SQoI8/ujH/PwCCogdmh6PR+PeeT5zufMfGbOOfFmzszgYRiGIQAAAAvwdHcDAAAAVYVgAwAALINgAwAALINgAwAALINgAwAALINgAwAALINgAwAALINgAwAALINgAwAALINgA1RzHTt2VMeOHd3dBm5SamqqPDw89M0337i7lV8kPgcoL4INfrVKftCUNU2aNMnd7VU7JfvmlVdeKTWvZF/u2rXLDZ3pmq9jaGioW/qpjG+++eaa23H1ZNVw9NVXX2n69OmW3T78PG5zdwOAu7344ouKiIhwGWvRooWbuqn+5syZoxEjRqhmzZrubsXFgw8+qAEDBriM+fr6uqmbigsKCtJf//pXl7FXXnlF33//vebOnVuq1oq++uorzZgxQx07dlSjRo1c5m3YsME9TeEXh2CDX71u3bqpVatW5aq9dOmSvL295en56zzYGRMToz179mjx4sVKSUlxdzsu7rrrLv33f/93uWoNw9ClS5eqVfCpVatWqf6XLVum8+fPX3e7quO23Are3t7ubgG/EL/O/zsD5bBlyxZ5eHho2bJlmjJlim6//XbVrFlTTqdT586d07hx4xQdHa3atWvLbrerW7du+vLLL12Wca3zKkqWvWXLFpfxJUuWqHHjxvL19VWbNm3073//u1y9tmjRQp06dSo1XlxcrNtvv12PPfaYObZs2TLFxsaqTp06stvtio6O1quvvlqu9bRr106dO3fW7NmzdfHixRvWb9q0Sffff79q1aolf39//fa3v9XXX3/tUjN9+nR5eHjoyJEjGjhwoPz9/eXn56dBgwbpxx9/LFdfN9KoUSM99NBDWr9+vVq1aiVfX1+98cYbkqR33nlHnTt3VnBwsGw2m6KiorRo0aJSy/Dw8ND06dPLXPbAgQNdxg4cOKDOnTvL19dXDRo00MyZM1VcXFxttqVkGZ988onatGkjHx8fRUZG6i9/+YtLXWFhoWbMmKEmTZrIx8dH9erV029+8xulp6ebNXv37tXAgQMVGRkpHx8fhYaG6qmnntLZs2dLrfc///mPBg8erLCwMNlsNkVERGjEiBEqKChQamqqHn/8cUlSp06dzK/dSj4jZZ1jc+rUKQ0ePFghISHy8fFRy5Yt9e6777rUlHzF97//+7/m58tms6l169b6/PPPXWodDocGDRqkBg0ayGazqX79+vrtb3/LV2O/MByxwa9ebm6uzpw54zIWGBho/vsPf/iDvL29NW7cOOXn58vb21tfffWVVq9erccff1wRERHKzs7WG2+8oQ4dOuirr75SWFhYhfv485//rKefflr33XefRo8erWPHjunhhx9WQECAwsPDr/vcPn36aPr06XI4HC7nlXzyySc6ceKE+vbtK0lKT09Xv3799MADD+jll1+WJH399dfavn27nnvuuXL1OX36dLVv316LFi267lGbf/3rX+rWrZsiIyM1ffp0Xbx4Ua+99pratWun3bt3l/qq4YknnlBERIRmzZql3bt366233lJwcLDZ541cunSp1OtYp04d2Ww2SdKhQ4fUr18/Pf300xo6dKjuvvtuSdKiRYvUvHlzPfzww7rtttu0Zs0aPfPMMyouLlZycnK51n0lh8OhTp066fLly5o0aZJq1aqlJUuWVOkRlarYliNHjuixxx7T4MGDlZSUpLffflsDBw5UbGysmjdvLumn13rWrFkaMmSI2rRpI6fTqV27dmn37t168MEHJf30njp27JgGDRqk0NBQHThwQEuWLNGBAwe0Y8cOeXh4SJJOnDihNm3aKCcnR8OGDVPTpk31n//8RytXrtSPP/6o9u3b69lnn9X8+fP1/PPPq1mzZpJk/vdqFy9eVMeOHXXkyBGNHDlSERERWrFihQYOHKicnJxS7+elS5fqhx9+0NNPPy0PDw/Nnj1bjz76qI4dO6YaNWpIknr37q0DBw5o1KhRatSokU6dOqX09HQdP3681PsV1ZgB/Eq98847hqQyJ8MwjM2bNxuSjMjISOPHH390ee6lS5eMoqIil7GsrCzDZrMZL774Yql1ZGVludSWLHvz5s2GYRhGQUGBERwcbMTExBj5+flm3ZIlSwxJRocOHa67LYcOHTIkGa+99prL+DPPPGPUrl3b7P+5554z7Ha7cfny5Rvun6tJMpKTkw3DMIxOnToZoaGh5nJLtvPzzz8362NiYozg4GDj7Nmz5tiXX35peHp6GgMGDDDHpk2bZkgynnrqKZf1PfLII0a9evXK3VtZ0zvvvGMYhmE0bNjQkGSkpaWVeu7Vr61hGEZiYqIRGRlZah3Tpk0rVduwYUMjKSnJfDx69GhDkvHZZ5+ZY6dOnTL8/PzKfC9cT48ePYyGDRuWWt/NbkvJMrZt2+bSo81mM8aOHWuOtWzZ0ujRo8d1eyxrnX//+99LLX/AgAGGp6eny3ukRHFxsWEYhrFixQqXz8WVOnTo4PI5mDdvniHJ+Nvf/maOFRQUGPHx8Ubt2rUNp9NpGMZPn0tJRr169Yxz586ZtR988IEhyVizZo1hGIZx/vx5Q5IxZ86c624vqj++isKv3sKFC5Wenu4yXSkpKanUb9s2m808z6aoqEhnz55V7dq1dffdd2v37t0V7mHXrl06deqUhg8f7nIuwcCBA+Xn53fD5991112KiYnR8uXLzbGioiKtXLlSPXv2NPv39/dXXl5eqW2sqJKjQ4sXLy5z/smTJ7Vnzx4NHDhQAQEB5vg999yjBx98UB999FGp5wwfPtzl8f3336+zZ8/K6XSWq6ff/va3pV7HxMREc35ERITL4xJXvrYlR+86dOigY8eOKTc3t1zrvtJHH32ktm3bqk2bNuZYUFCQ+vfvX+FlXUtVbEtUVJTuv/9+lx7vvvtuHTt2zBzz9/fXgQMHdPjw4Wv2cuU6S46atW3bVpLMz0JxcbFWr16tnj17lnk+W8lRnYr46KOPFBoaqn79+pljNWrU0LPPPqsLFy5o69atLvV9+vRR3bp1zccl216yvb6+vvL29taWLVt0/vz5CveD6oNgg1+9Nm3aKCEhwWW60tVXTEk//Y967ty5atKkiWw2mwIDAxUUFKS9e/dW6ofht99+K0lq0qSJy3iNGjUUGRlZrmX06dNH27dv13/+8x9JP53Hc+rUKfXp08eseeaZZ3TXXXepW7duatCggZ566imlpaVVuN/27durU6dO1zzXpmR7Sr4iuVKzZs105swZ5eXluYzfcccdLo9LfgiV/JA5d+6cHA6HOV29nxs0aFDqdaxfv745v6zXUZK2b9+uhIQE8zygoKAgPf/885JU6dfy6tdRKntfVFZVbMvV+1v6aZ9f+UP9xRdfVE5Oju666y5FR0dr/Pjx2rt3r8tzzp07p+eee04hISHy9fVVUFCQ2V/JOk+fPi2n01mlVxuW7OerT+Qv+eqq5D1Y4kbvL5vNppdfflkff/yxQkJC1L59e82ePVsOh6PKesbPg2AD3EBZ50b88Y9/VEpKitq3b6+//e1vWr9+vdLT09W8eXOXk0Sv9ZtoUVFRlffZp08fGYahFStWSJLef/99+fn5qWvXrmZNcHCw9uzZow8//FAPP/ywNm/erG7duikpKanC65s2bZocDod54urN8vLyKnPcMAxJ0qOPPqr69eubU3nPCSpR1ut49OhRPfDAAzpz5oz+9Kc/ad26dUpPT9eYMWMkqVwn/N6K1/JGqmJbbrS/pZ8C7NGjR/X222+rRYsWeuutt3TvvffqrbfeMmueeOIJvfnmmxo+fLj++c9/asOGDWZYrqoTpqtCebZ39OjR+r//+z/NmjVLPj4+euGFF9SsWTN98cUXP1ebqAKcPAxUwsqVK9WpUyf9+c9/dhnPyclxOfG45LfCnJwcl7qrf5ts2LChJOnw4cPq3LmzOV5YWKisrCy1bNnyhj1FRESoTZs2Wr58uUaOHKl//vOf6tWrl3nybAlvb2/17NlTPXv2VHFxsZ555hm98cYbeuGFF3TnnXfeeOP/vw4dOqhjx456+eWXNXXq1DK359ChQ6Wed/DgQQUGBqpWrVrlXpf00z1drjyaUJkTtK+2Zs0a5efn68MPP3T5jX7z5s2lauvWrVvqdSwoKNDJkyddxho2bFjmVzdl7YuqVJFtqYiAgAANGjRIgwYN0oULF9S+fXtNnz5dQ4YM0fnz57Vx40bNmDHD5T1w9fYHBQXJbrdr//79111XRb6Satiwofbu3avi4mKXozYHDx4051dG48aNNXbsWI0dO1aHDx9WTEyMXnnlFf3tb3+r1PLw8+OIDVAJXl5eLr/pSdKKFSvMr4FKNG7cWJK0bds2c6yoqEhLlixxqWvVqpWCgoK0ePFiFRQUmOOpqamlfpheT58+fbRjxw69/fbbOnPmjMvXUJJKXYLr6empe+65R5KUn59f7vWUKDnX5urtqV+/vmJiYvTuu++69L9//35t2LBB3bt3r/C6YmNjXb5mioqKqvAyrlbyW/yVr2Vubq7eeeedUrWNGzd2eR2lny7Pv/qITffu3bVjxw7t3LnTHDt9+rTee++9m+73eiqyLeV19fuldu3auvPOO833SlnrlKR58+a5PPb09FSvXr20Zs2aMu9OXfL8krBbnvd89+7d5XA4XM4ru3z5sl577TXVrl1bHTp0uOEyrvTjjz/q0qVLLmONGzdWnTp1KvXZgPtwxAaohIceekgvvviiBg0apPvuu0/79u3Te++9V+p8mObNm6tt27aaPHmyzp07p4CAAC1btkyXL192qatRo4Zmzpypp59+Wp07d1afPn2UlZWld955p9zn2Eg/fS0wbtw4jRs3TgEBAaXOFxoyZIjOnTunzp07q0GDBvr222/12muvKSYm5pqX1V5Phw4d1KFDh1Inako/3aG4W7duio+P1+DBg83Lvf38/Mq8H4w7dOnSxTyC9fTTT+vChQt68803FRwcXOpIzJAhQzR8+HD17t1bDz74oL788kutX7/e5QidJE2YMEF//etf1bVrVz333HPm5d4lRxiqw7aUV1RUlDp27KjY2FgFBARo165dWrlypUaOHClJstvt5rkohYWFuv3227VhwwZlZWWVWtYf//hHbdiwQR06dNCwYcPUrFkznTx5UitWrNAnn3wif39/xcTEyMvLSy+//LJyc3Nls9nM+/JcbdiwYXrjjTc0cOBAZWZmqlGjRlq5cqW2b9+uefPmqU6dOhXa1v/7v//TAw88oCeeeEJRUVG67bbbtGrVKmVnZ5u3S8AvhNuuxwLcrKxLlK9Uckn2ihUrSs27dOmSMXbsWKN+/fqGr6+v0a5dOyMjI6PUJamGYRhHjx41EhISDJvNZoSEhBjPP/+8kZ6eXuZlra+//roRERFh2Gw2o1WrVsa2bdvKXOb1tGvXzpBkDBkypNS8lStXGl26dDGCg4MNb29v44477jCefvpp4+TJkzdcrq643PtKJfuprH35r3/9y2jXrp3h6+tr2O12o2fPnsZXX33lUlNyuffp06ddxq91qXxFeivRsGHDa162/OGHHxr33HOP4ePjYzRq1Mh4+eWXjbfffrvUuouKioyJEycagYGBRs2aNY3ExETjyJEjpS73NgzD2Lt3r9GhQwfDx8fHuP32240//OEPxp///Ocqu9z7ZrflWsu4+r02c+ZMo02bNoa/v7/h6+trNG3a1HjppZeMgoICs+b77783HnnkEcPf39/w8/MzHn/8cePEiRNlXh7/7bffGgMGDDCCgoIMm81mREZGGsnJyS63OHjzzTeNyMhIw8vLy+UzUtbnIDs72xg0aJARGBhoeHt7G9HR0eYl/iVKLvcu6zLuK3s8c+aMkZycbDRt2tSoVauW4efnZ8TFxRnvv/9+mfsa1ZeHYVx1DBEAAOAXinNsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZXCDvp9RcXGxTpw4oTp16lTqr9kCAPBrZRiGfvjhB4WFhZX646dXItj8jE6cOKHw8HB3twEAwC/Wd999pwYNGlxzPsHmZ1Ryi+/vvvtOdrvdzd0AAPDL4XQ6FR4efsM/l0Gw+RmVfP1kt9sJNgAAVMKNTuXg5GEAAGAZBBsAAGAZBBsAAGAZBBsAAGAZBBsAAGAZBBsAAGAZBBsAAGAZBBsAAGAZBBsAAGAZBBsAAGAZBBsAAGAZ/K0oC4kd/xd3twDccplzBri7BQDVGEdsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZbg12MyaNUutW7dWnTp1FBwcrF69eunQoUMuNR07dpSHh4fLNHz4cJea48ePq0ePHqpZs6aCg4M1fvx4Xb582aVmy5Ytuvfee2Wz2XTnnXcqNTW1VD8LFy5Uo0aN5OPjo7i4OO3cudNl/qVLl5ScnKx69eqpdu3a6t27t7Kzs6tmZwAAgJvm1mCzdetWJScna8eOHUpPT1dhYaG6dOmivLw8l7qhQ4fq5MmT5jR79mxzXlFRkXr06KGCggJ9+umnevfdd5WamqqpU6eaNVlZWerRo4c6deqkPXv2aPTo0RoyZIjWr19v1ixfvlwpKSmaNm2adu/erZYtWyoxMVGnTp0ya8aMGaM1a9ZoxYoV2rp1q06cOKFHH330Fu4hAABQER6GYRjubqLE6dOnFRwcrK1bt6p9+/aSfjpiExMTo3nz5pX5nI8//lgPPfSQTpw4oZCQEEnS4sWLNXHiRJ0+fVre3t6aOHGi1q1bp/3795vP69u3r3JycpSWliZJiouLU+vWrbVgwQJJUnFxscLDwzVq1ChNmjRJubm5CgoK0tKlS/XYY49Jkg4ePKhmzZopIyNDbdu2veH2OZ1O+fn5KTc3V3a7vdL76Vpix/+lypcJVDeZcwa4uwUAblDen6HV6hyb3NxcSVJAQIDL+HvvvafAwEC1aNFCkydP1o8//mjOy8jIUHR0tBlqJCkxMVFOp1MHDhwwaxISElyWmZiYqIyMDElSQUGBMjMzXWo8PT2VkJBg1mRmZqqwsNClpmnTprrjjjvMmqvl5+fL6XS6TAAA4Na5zd0NlCguLtbo0aPVrl07tWjRwhz/3e9+p4YNGyosLEx79+7VxIkTdejQIf3zn/+UJDkcDpdQI8l87HA4rlvjdDp18eJFnT9/XkVFRWXWHDx40FyGt7e3/P39S9WUrOdqs2bN0owZMyq4JwAAQGVVm2CTnJys/fv365NPPnEZHzZsmPnv6Oho1a9fXw888ICOHj2qxo0b/9xtVsjkyZOVkpJiPnY6nQoPD3djRwAAWFu1+Cpq5MiRWrt2rTZv3qwGDRpctzYuLk6SdOTIEUlSaGhoqSuTSh6HhoZet8Zut8vX11eBgYHy8vIqs+bKZRQUFCgnJ+eaNVez2Wyy2+0uEwAAuHXcGmwMw9DIkSO1atUqbdq0SRERETd8zp49eyRJ9evXlyTFx8dr3759Llcvpaeny263KyoqyqzZuHGjy3LS09MVHx8vSfL29lZsbKxLTXFxsTZu3GjWxMbGqkaNGi41hw4d0vHjx80aAADgXm79Kio5OVlLly7VBx98oDp16pjnqvj5+cnX11dHjx7V0qVL1b17d9WrV0979+7VmDFj1L59e91zzz2SpC5duigqKkpPPvmkZs+eLYfDoSlTpig5OVk2m02SNHz4cC1YsEATJkzQU089pU2bNun999/XunXrzF5SUlKUlJSkVq1aqU2bNpo3b57y8vI0aNAgs6fBgwcrJSVFAQEBstvtGjVqlOLj48t1RRQAALj13BpsFi1aJOmnS7qv9M4772jgwIHy9vbWv/71LzNkhIeHq3fv3poyZYpZ6+XlpbVr12rEiBGKj49XrVq1lJSUpBdffNGsiYiI0Lp16zRmzBi9+uqratCggd566y0lJiaaNX369NHp06c1depUORwOxcTEKC0tzeWE4rlz58rT01O9e/dWfn6+EhMT9frrr9+ivQMAACqqWt3Hxuq4jw1w87iPDfDr9Iu8jw0AAMDNINgAAADLINgAAADLINgAAADLINgAAADLINgAAADLINgAAADLINgAAADLINgAAADLINgAAADLINgAAADLINgAAADLINgAAADLINgAAADLINgAAADLINgAAADLINgAAADLINgAAADLINgAAADLINgAAADLINgAAADLINgAAADLINgAAADLINgAAADLINgAAADLINgAAADLINgAAADLINgAAADLINgAAADLINgAAADLINgAAADLINgAAADLINgAAADLINgAAADLINgAAADLINgAAADLINgAAADLINgAAADLINgAAADLINgAAADLcGuwmTVrllq3bq06deooODhYvXr10qFDh1xqLl26pOTkZNWrV0+1a9dW7969lZ2d7VJz/Phx9ejRQzVr1lRwcLDGjx+vy5cvu9Rs2bJF9957r2w2m+68806lpqaW6mfhwoVq1KiRfHx8FBcXp507d1a4FwAA4D5uDTZbt25VcnKyduzYofT0dBUWFqpLly7Ky8sza8aMGaM1a9ZoxYoV2rp1q06cOKFHH33UnF9UVKQePXqooKBAn376qd59912lpqZq6tSpZk1WVpZ69OihTp06ac+ePRo9erSGDBmi9evXmzXLly9XSkqKpk2bpt27d6tly5ZKTEzUqVOnyt0LAABwLw/DMAx3N1Hi9OnTCg4O1tatW9W+fXvl5uYqKChIS5cu1WOPPSZJOnjwoJo1a6aMjAy1bdtWH3/8sR566CGdOHFCISEhkqTFixdr4sSJOn36tLy9vTVx4kStW7dO+/fvN9fVt29f5eTkKC0tTZIUFxen1q1ba8GCBZKk4uJihYeHa9SoUZo0aVK5erkRp9MpPz8/5ebmym63V+m+k6TY8X+p8mUC1U3mnAHubgGAG5T3Z2i1OscmNzdXkhQQECBJyszMVGFhoRISEsyapk2b6o477lBGRoYkKSMjQ9HR0WaokaTExEQ5nU4dOHDArLlyGSU1JcsoKChQZmamS42np6cSEhLMmvL0crX8/Hw5nU6XCQAA3DrVJtgUFxdr9OjRateunVq0aCFJcjgc8vb2lr+/v0ttSEiIHA6HWXNlqCmZXzLvejVOp1MXL17UmTNnVFRUVGbNlcu4US9XmzVrlvz8/MwpPDy8nHsDAABURrUJNsnJydq/f7+WLVvm7laqzOTJk5Wbm2tO3333nbtbAgDA0m5zdwOSNHLkSK1du1bbtm1TgwYNzPHQ0FAVFBQoJyfH5UhJdna2QkNDzZqrr14quVLpypqrr17Kzs6W3W6Xr6+vvLy85OXlVWbNlcu4US9Xs9lsstlsFdgTAADgZrj1iI1hGBo5cqRWrVqlTZs2KSIiwmV+bGysatSooY0bN5pjhw4d0vHjxxUfHy9Jio+P1759+1yuXkpPT5fdbldUVJRZc+UySmpKluHt7a3Y2FiXmuLiYm3cuNGsKU8vAADAvdx6xCY5OVlLly7VBx98oDp16pjnqvj5+cnX11d+fn4aPHiwUlJSFBAQILvdrlGjRik+Pt68CqlLly6KiorSk08+qdmzZ8vhcGjKlClKTk42j5YMHz5cCxYs0IQJE/TUU09p06ZNev/997Vu3Tqzl5SUFCUlJalVq1Zq06aN5s2bp7y8PA0aNMjs6Ua9AAAA93JrsFm0aJEkqWPHji7j77zzjgYOHChJmjt3rjw9PdW7d2/l5+crMTFRr7/+ulnr5eWltWvXasSIEYqPj1etWrWUlJSkF1980ayJiIjQunXrNGbMGL366qtq0KCB3nrrLSUmJpo1ffr00enTpzV16lQ5HA7FxMQoLS3N5YTiG/UCAADcq1rdx8bquI8NcPO4jw3w6/SLvI8NAADAzSDYAAAAyyDYAAAAyyDYAAAAyyDYAAAAyyDYAAAAyyDYAAAAyyDYAAAAyyDYAAAAyyDYAAAAyyDYAAAAyyDYAAAAyyDYAAAAyyDYAAAAyyDYAAAAyyDYAAAAyyDYAAAAyyDYAAAAyyDYAAAAyyDYAAAAyyDYAAAAyyDYAAAAyyDYAAAAyyDYAAAAyyDYAAAAyyDYAAAAyyDYAAAAyyDYAAAAyyDYAAAAy6hUsOncubNycnJKjTudTnXu3PlmewIAAKiUSgWbLVu2qKCgoNT4pUuX9O9///ummwIAAKiM2ypSvHfvXvPfX331lRwOh/m4qKhIaWlpuv3226uuOwAAgAqoULCJiYmRh4eHPDw8yvzKydfXV6+99lqVNQcAAFARFQo2WVlZMgxDkZGR2rlzp4KCgsx53t7eCg4OlpeXV5U3CQAAUB4VCjYNGzaUJBUXF9+SZgAAAG5GhYLNlQ4fPqzNmzfr1KlTpYLO1KlTb7oxAACAiqpUsHnzzTc1YsQIBQYGKjQ0VB4eHuY8Dw8Pgg0AAHCLSgWbmTNn6qWXXtLEiROruh8AAIBKq9R9bM6fP6/HH3+8qnsBAAC4KZUKNo8//rg2bNhQ1b0AAADclEp9FXXnnXfqhRde0I4dOxQdHa0aNWq4zH/22WerpDkAAICKqNQRmyVLlqh27draunWrFixYoLlz55rTvHnzyr2cbdu2qWfPngoLC5OHh4dWr17tMn/gwIHmDQFLpq5du7rUnDt3Tv3795fdbpe/v78GDx6sCxcuuNTs3btX999/v3x8fBQeHq7Zs2eX6mXFihVq2rSpfHx8FB0drY8++shlvmEYmjp1qurXry9fX18lJCTo8OHD5d5WAABw61Uq2GRlZV1zOnbsWLmXk5eXp5YtW2rhwoXXrOnatatOnjxpTn//+99d5vfv318HDhxQenq61q5dq23btmnYsGHmfKfTqS5duqhhw4bKzMzUnDlzNH36dC1ZssSs+fTTT9WvXz8NHjxYX3zxhXr16qVevXpp//79Zs3s2bM1f/58LV68WJ999plq1aqlxMREXbp0qdzbCwAAbi0PwzAMdzch/XSZ+KpVq9SrVy9zbODAgcrJySl1JKfE119/raioKH3++edq1aqVJCktLU3du3fX999/r7CwMC1atEi///3v5XA45O3tLUmaNGmSVq9erYMHD0qS+vTpo7y8PK1du9Zcdtu2bRUTE6PFixfLMAyFhYVp7NixGjdunCQpNzdXISEhSk1NVd++fcu1jU6nU35+fsrNzZXdbq/oLrqh2PF/qfJlAtVN5pwB7m4BgBuU92dopc6xeeqpp647/+23367MYsu0ZcsWBQcHq27duurcubNmzpypevXqSZIyMjLk7+9vhhpJSkhIkKenpz777DM98sgjysjIUPv27c1QI0mJiYl6+eWXdf78edWtW1cZGRlKSUlxWW9iYqIZqLKysuRwOJSQkGDO9/PzU1xcnDIyMq4ZbPLz85Wfn28+djqdN70/AADAtVUq2Jw/f97lcWFhofbv36+cnJwy/zhmZXXt2lWPPvqoIiIidPToUT3//PPq1q2bMjIy5OXlJYfDoeDgYJfn3HbbbQoICDD/8rjD4VBERIRLTUhIiDmvbt26cjgc5tiVNVcu48rnlVVTllmzZmnGjBmV2HIAAFAZlQo2q1atKjVWXFysESNGqHHjxjfdVIkrj4RER0frnnvuUePGjbVlyxY98MADVbaeW2Xy5MkuR4KcTqfCw8Pd2BEAANZWqZOHy1yQp6dSUlI0d+7cqlpkKZGRkQoMDNSRI0ckSaGhoTp16pRLzeXLl3Xu3DmFhoaaNdnZ2S41JY9vVHPl/CufV1ZNWWw2m+x2u8sEAABunSoLNpJ09OhRXb58uSoX6eL777/X2bNnVb9+fUlSfHy8cnJylJmZadZs2rRJxcXFiouLM2u2bdumwsJCsyY9PV1333236tata9Zs3LjRZV3p6emKj4+XJEVERCg0NNSlxul06rPPPjNrAACA+1Xqq6irT7Q1DEMnT57UunXrlJSUVO7lXLhwwTz6Iv10ku6ePXsUEBCggIAAzZgxQ71791ZoaKiOHj2qCRMm6M4771RiYqIkqVmzZuratauGDh2qxYsXq7CwUCNHjlTfvn0VFhYmSfrd736nGTNmaPDgwZo4caL279+vV1991eXI0nPPPacOHTrolVdeUY8ePbRs2TLt2rXLvCTcw8NDo0eP1syZM9WkSRNFRETohRdeUFhYmMtVXAAAwL0qFWy++OILl8eenp4KCgrSK6+8csMrpq60a9cuderUyXxcEpiSkpK0aNEi7d27V++++65ycnIUFhamLl266A9/+INsNpv5nPfee08jR47UAw88IE9PT/Xu3Vvz58835/v5+WnDhg1KTk5WbGysAgMDNXXqVJd73dx3331aunSppkyZoueff15NmjTR6tWr1aJFC7NmwoQJysvL07Bhw5STk6Pf/OY3SktLk4+PT/l3HAAAuKWqzX1sfg24jw1w87iPDfDrdEvvY1Pi9OnTOnTokCTp7rvvVlBQ0M0sDgAA4KZU6uThvLw8PfXUU6pfv77at2+v9u3bKywsTIMHD9aPP/5Y1T0CAACUS6WCTUpKirZu3ao1a9YoJydHOTk5+uCDD7R161aNHTu2qnsEAAAol0p9FfWPf/xDK1euVMeOHc2x7t27y9fXV0888YQWLVpUVf0BAACUW6WO2Pz444+l/ryAJAUHB/NVFAAAcJtKBZv4+HhNmzZNly5dMscuXryoGTNmcMM6AADgNpX6KmrevHnq2rWrGjRooJYtW0qSvvzyS9lsNm3YsKFKGwQAACivSgWb6OhoHT58WO+9954OHjwoSerXr5/69+8vX1/fKm0QAACgvCoVbGbNmqWQkBANHTrUZfztt9/W6dOnNXHixCppDgAAoCIqdY7NG2+8oaZNm5Yab968uRYvXnzTTQEAAFRGpYKNw+Ew/8L2lYKCgnTy5MmbbgoAAKAyKhVswsPDtX379lLj27dvN/+qNgAAwM+tUufYDB06VKNHj1ZhYaE6d+4sSdq4caMmTJjAnYcBAIDbVCrYjB8/XmfPntUzzzyjgoICSZKPj48mTpyoyZMnV2mDAAAA5VWpYOPh4aGXX35ZL7zwgr7++mv5+vqqSZMmstlsVd0fAABAuVUq2JSoXbu2WrduXVW9AAAA3JRKnTwMAABQHRFsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZbg12Gzbtk09e/ZUWFiYPDw8tHr1apf5hmFo6tSpql+/vnx9fZWQkKDDhw+71Jw7d079+/eX3W6Xv7+/Bg8erAsXLrjU7N27V/fff798fHwUHh6u2bNnl+plxYoVatq0qXx8fBQdHa2PPvqowr0AAAD3cmuwycvLU8uWLbVw4cIy58+ePVvz58/X4sWL9dlnn6lWrVpKTEzUpUuXzJr+/fvrwIEDSk9P19q1a7Vt2zYNGzbMnO90OtWlSxc1bNhQmZmZmjNnjqZPn64lS5aYNZ9++qn69eunwYMH64svvlCvXr3Uq1cv7d+/v0K9AAAA9/IwDMNwdxOS5OHhoVWrVqlXr16SfjpCEhYWprFjx2rcuHGSpNzcXIWEhCg1NVV9+/bV119/raioKH3++edq1aqVJCktLU3du3fX999/r7CwMC1atEi///3v5XA45O3tLUmaNGmSVq9erYMHD0qS+vTpo7y8PK1du9bsp23btoqJidHixYvL1Ut5OJ1O+fn5KTc3V3a7vUr225Vix/+lypcJVDeZcwa4uwUAblDen6HV9hybrKwsORwOJSQkmGN+fn6Ki4tTRkaGJCkjI0P+/v5mqJGkhIQEeXp66rPPPjNr2rdvb4YaSUpMTNShQ4d0/vx5s+bK9ZTUlKynPL2UJT8/X06n02UCAAC3TrUNNg6HQ5IUEhLiMh4SEmLOczgcCg4Odpl/2223KSAgwKWmrGVcuY5r1Vw5/0a9lGXWrFny8/Mzp/Dw8BtsNQAAuBnVNthYweTJk5Wbm2tO3333nbtbAgDA0qptsAkNDZUkZWdnu4xnZ2eb80JDQ3Xq1CmX+ZcvX9a5c+dcaspaxpXruFbNlfNv1EtZbDab7Ha7ywQAAG6dahtsIiIiFBoaqo0bN5pjTqdTn332meLj4yVJ8fHxysnJUWZmplmzadMmFRcXKy4uzqzZtm2bCgsLzZr09HTdfffdqlu3rllz5XpKakrWU55eAACA+7k12Fy4cEF79uzRnj17JP10ku6ePXt0/PhxeXh4aPTo0Zo5c6Y+/PBD7du3TwMGDFBYWJh55VSzZs3UtWtXDR06VDt37tT27ds1cuRI9e3bV2FhYZKk3/3ud/L29tbgwYN14MABLV++XK+++qpSUlLMPp577jmlpaXplVde0cGDBzV9+nTt2rVLI0eOlKRy9QIAANzvNneufNeuXerUqZP5uCRsJCUlKTU1VRMmTFBeXp6GDRumnJwc/eY3v1FaWpp8fHzM57z33nsaOXKkHnjgAXl6eqp3796aP3++Od/Pz08bNmxQcnKyYmNjFRgYqKlTp7rc6+a+++7T0qVLNWXKFD3//PNq0qSJVq9erRYtWpg15ekFAAC4V7W5j82vAfexAW4e97EBfp1+8fexAQAAqCiCDQAAsAyCDQAAsAyCDQAAsAyCDQAAsAyCDQAAsAyCDQAAsAyCDQAAsAyCDQAAsAyCDQAAsAyCDQAAsAyCDQAAsAyCDQAAsAyCDQAAsAyCDQAAsAyCDQAAsAyCDQAAsAyCDQAAsAyCDQAAsAyCDQAAsAyCDQAAsAyCDQAAsAyCDQAAsAyCDQAAsAyCDQAAsAyCDQAAsAyCDQAAsAyCDQAAsAyCDQAAsAyCDQAAsAyCDQAAsAyCDQAAsAyCDQAAsAyCDQAAsAyCDQAAsAyCDQAAsAyCDQAAsAyCDQAAsAyCDQAAsAyCDQAAsIxqHWymT58uDw8Pl6lp06bm/EuXLik5OVn16tVT7dq11bt3b2VnZ7ss4/jx4+rRo4dq1qyp4OBgjR8/XpcvX3ap2bJli+69917ZbDbdeeedSk1NLdXLwoUL1ahRI/n4+CguLk47d+68JdsMAAAqr1oHG0lq3ry5Tp48aU6ffPKJOW/MmDFas2aNVqxYoa1bt+rEiRN69NFHzflFRUXq0aOHCgoK9Omnn+rdd99Vamqqpk6datZkZWWpR48e6tSpk/bs2aPRo0dryJAhWr9+vVmzfPlypaSkaNq0adq9e7datmypxMREnTp16ufZCQAAoFw8DMMw3N3EtUyfPl2rV6/Wnj17Ss3Lzc1VUFCQli5dqscee0ySdPDgQTVr1kwZGRlq27atPv74Yz300EM6ceKEQkJCJEmLFy/WxIkTdfr0aXl7e2vixIlat26d9u/fby67b9++ysnJUVpamiQpLi5OrVu31oIFCyRJxcXFCg8P16hRozRp0qRyb4/T6ZSfn59yc3Nlt9sru1uuKXb8X6p8mUB1kzlngLtbAOAG5f0ZWu2P2Bw+fFhhYWGKjIxU//79dfz4cUlSZmamCgsLlZCQYNY2bdpUd9xxhzIyMiRJGRkZio6ONkONJCUmJsrpdOrAgQNmzZXLKKkpWUZBQYEyMzNdajw9PZWQkGDWXEt+fr6cTqfLBAAAbp1qHWzi4uKUmpqqtLQ0LVq0SFlZWbr//vv1ww8/yOFwyNvbW/7+/i7PCQkJkcPhkCQ5HA6XUFMyv2Te9WqcTqcuXryoM2fOqKioqMyakmVcy6xZs+Tn52dO4eHhFd4HAACg/G5zdwPX061bN/Pf99xzj+Li4tSwYUO9//778vX1dWNn5TN58mSlpKSYj51OJ+EGAIBbqFofsbmav7+/7rrrLh05ckShoaEqKChQTk6OS012drZCQ0MlSaGhoaWukip5fKMau90uX19fBQYGysvLq8yakmVci81mk91ud5kAAMCt84sKNhcuXNDRo0dVv359xcbGqkaNGtq4caM5/9ChQzp+/Lji4+MlSfHx8dq3b5/L1Uvp6emy2+2Kiooya65cRklNyTK8vb0VGxvrUlNcXKyNGzeaNQAAoHqo1sFm3Lhx2rp1q7755ht9+umneuSRR+Tl5aV+/frJz89PgwcPVkpKijZv3qzMzEwNGjRI8fHxatu2rSSpS5cuioqK0pNPPqkvv/xS69ev15QpU5ScnCybzSZJGj58uI4dO6YJEybo4MGDev311/X+++9rzJgxZh8pKSl688039e677+rrr7/WiBEjlJeXp0GDBrllvwAAgLJV63Nsvv/+e/Xr109nz55VUFCQfvOb32jHjh0KCgqSJM2dO1eenp7q3bu38vPzlZiYqNdff918vpeXl9auXasRI0YoPj5etWrVUlJSkl588UWzJiIiQuvWrdOYMWP06quvqkGDBnrrrbeUmJho1vTp00enT5/W1KlT5XA4FBMTo7S0tFInFAMAAPeq1vexsRruYwPcPO5jA/w6WeY+NgAAAOVFsAEAAJZBsAEAAJZBsAEAAJZBsAEAAJZBsAEAAJZBsAEAAJZBsAEAAJZBsAEAAJZBsAEAAJZBsAEAAJZBsAEAAJZBsAEAAJZBsAEAAJZBsAEAAJZBsAEAAJZBsAEAAJZBsAEAAJZBsAEAAJZBsAEAAJZBsAEAAJZBsAEAAJZBsAEAAJZBsAEAAJZBsAEAAJZBsAEAAJZBsAEAAJZBsAEAAJZBsAEAAJZBsAEAAJZBsAEAAJZBsAEAAJZBsAEAAJZBsAEAAJZBsAEAAJZBsAEAAJZBsAEAAJZBsAEAAJZBsAEAAJZBsAEAAJZBsAEAAJZBsKmghQsXqlGjRvLx8VFcXJx27tzp7pYAAMD/R7CpgOXLlyslJUXTpk3T7t271bJlSyUmJurUqVPubg0AAIhgUyF/+tOfNHToUA0aNEhRUVFavHixatasqbffftvdrQEAAEm3ubuBX4qCggJlZmZq8uTJ5pinp6cSEhKUkZFR5nPy8/OVn59vPs7NzZUkOZ3OW9JjUf7FW7JcoDq5VZ+fn0P7KX93dwvALbdtZr9bstySz75hGNetI9iU05kzZ1RUVKSQkBCX8ZCQEB08eLDM58yaNUszZswoNR4eHn5LegR+DfxeG+7uFgBcx63+jP7www/y8/O75nyCzS00efJkpaSkmI+Li4t17tw51atXTx4eHm7sDFXB6XQqPDxc3333nex2u7vbAXAVPqPWYhiGfvjhB4WFhV23jmBTToGBgfLy8lJ2drbLeHZ2tkJDQ8t8js1mk81mcxnz9/e/VS3CTex2O//TBKoxPqPWcb0jNSU4ebicvL29FRsbq40bN5pjxcXF2rhxo+Lj493YGQAAKMERmwpISUlRUlKSWrVqpTZt2mjevHnKy8vToEGD3N0aAAAQwaZC+vTpo9OnT2vq1KlyOByKiYlRWlpaqROK8etgs9k0bdq0Ul83Aqge+Iz+OnkYN7puCgAA4BeCc2wAAIBlEGwAAIBlEGwAAIBlEGwAAIBlEGyASlq4cKEaNWokHx8fxcXFaefOne5uCYCkbdu2qWfPngoLC5OHh4dWr17t7pbwMyLYAJWwfPlypaSkaNq0adq9e7datmypxMREnTp1yt2tAb96eXl5atmypRYuXOjuVuAGXO4NVEJcXJxat26tBQsWSPrpLtTh4eEaNWqUJk2a5ObuAJTw8PDQqlWr1KtXL3e3gp8JR2yACiooKFBmZqYSEhLMMU9PTyUkJCgjI8ONnQEACDZABZ05c0ZFRUWl7jgdEhIih8Phpq4AABLBBgAAWAjBBqigwMBAeXl5KTs722U8OztboaGhbuoKACARbIAK8/b2VmxsrDZu3GiOFRcXa+PGjYqPj3djZwAA/ro3UAkpKSlKSkpSq1at1KZNG82bN095eXkaNGiQu1sDfvUuXLigI0eOmI+zsrK0Z88eBQQE6I477nBjZ/g5cLk3UEkLFizQnDlz5HA4FBMTo/nz5ysuLs7dbQG/elu2bFGnTp1KjSclJSk1NfXnbwg/K4INAACwDM6xAQAAlkGwAQAAlkGwAQAAlkGwAQAAlkGwAQAAlkGwAQAAlkGwAQAAlkGwAQAAlkGwAfCr4uHhodWrV7u7DQC3CMEGgKU4HA6NGjVKkZGRstlsCg8PV8+ePV3+aCkA6+KPYAKwjG+++Ubt2rWTv7+/5syZo+joaBUWFmr9+vVKTk7WwYMH3d0igFuMIzYALOOZZ56Rh4eHdu7cqd69e+uuu+5S8+bNlZKSoh07dpT5nIkTJ+quu+5SzZo1FRkZqRdeeEGFhYXm/C+//FKdOnVSnTp1ZLfbFRsbq127dkmSvv32W/Xs2VN169ZVrVq11Lx5c3300Uc/y7YCKBtHbABYwrlz55SWlqaXXnpJtWrVKjXf39+/zOfVqVNHqampCgsL0759+zR06FDVqVNHEyZMkCT1799f//Vf/6VFixbJy8tLe/bsUY0aNSRJycnJKigo0LZt21SrVi199dVXql279i3bRgA3RrABYAlHjhyRYRhq2rRphZ43ZcoU89+NGjXSuHHjtGzZMjPYHD9+XOPHjzeX26RJE7P++PHj6t27t6KjoyVJkZGRN7sZAG4SX0UBsATDMCr1vOXLl6tdu3YKDQ1V7dq1NWXKFB0/ftycn5KSoiFDhighIUH/8z//o6NHj5rznn32Wc2cOVPt2rXTtGnTtHfv3pveDgA3h2ADwBKaNGkiDw+PCp0gnJGRof79+6t79+5au3atvvjiC/3+979XQUGBWTN9+nQdOHBAPXr00KZNmxQVFaVVq1ZJkoYMGaJjx47pySef1L59+9SqVSu99tprVb5tAMrPw6jsrzkAUM1069ZN+/bt06FDh0qdZ5OTkyN/f395eHho1apV6tWrl1555RW9/vrrLkdhhgwZopUrVyonJ6fMdfTr1095eXn68MMPS82bPHmy1q1bx5EbwI04YgPAMhYuXKiioiK1adNG//jHP3T48GF9/fXXmj9/vuLj40vVN2nSRMePH9eyZct09OhRzZ8/3zwaI0kXL17UyJEjtWXLFn377bfavn27Pv/8czVr1kySNHr0aK1fv15ZWVnavXu3Nm/ebM4D4B6cPAzAMiIjI7V792699NJLGjt2rE6ePKmgoCDFxsZq0aJFpeoffvhhjRkzRiNHjlR+fr569OihF154QdOnT5ckeXl56ezZsxowYICys7MVGBioRx99VDNmzJAkFRUVKTk5Wd9//73sdru6du2quXPn/pybDOAqfBUFAAAsg6+iAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZRBsAACAZfw/06Xmhm+i9NQAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "\n",
        "This project demonstrates how machine learning can be applied to anomaly detection problems.\n",
        "\n",
        "Fraud detection in banking systems and intrusion detection in cybersecurity share similar principles: both involve identifying abnormal patterns in large-scale data.\n",
        "\n",
        "Through this project, I understood that AI is not only about prediction but also about supporting decision-making in real-world environments. This strengthened my interest in applied artificial intelligence and motivated me to pursue advanced study in intelligent data-driven systems.\n"
      ],
      "metadata": {
        "id": "9BLOQ-zqmQrF"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s-6OhYdMmOsV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}